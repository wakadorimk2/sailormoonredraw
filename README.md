# Sailormoonredraw Generative Model
セーラームーンの二次創作イラストを使って、画像生成モデルを作成します。  
Develop a image generative model by using sailormoonredraw illustrations.

# sailormoonredrawとは
2020年の春頃、Twitterのイラストレーターの間で「セーラームーンのイラストを自分流にアレンジして描く」という投稿が流行しました。

有名なシーンの一枚絵を元にして、それはもう色々な派生が作られました。

https://twitter.com/Koushun1022/status/1261937834744623105

基本的にはイラストレーターの個性を全面に押し出したパターンが多いです。

https://twitter.com/m0721804/status/1261975273475432448

https://twitter.com/Souryu_STD/status/1261760323477889025

他にも有名な漫画であるジョジョ風にしたりとか、多様性に富んでます。

https://twitter.com/asikoh009/status/1262059435012157440

# なぜ画像生成をするのか
今回の事例で重要なのは「キャラクターも背景も構図も同じイラストを、世界中の多くのイラストレーターが描いた」という点です。
当時のタイムラインに居たのですが、それはもう毎日同じようなイラストが沢山流れてくるので、正直飽きるほどでした。

しかし今回の事例は、画像生成モデルを作成する際の「データセットの画像が多様性が高すぎて学習に失敗する」という課題を解決しそうなことに気付きました。

本モデルの目的は「実際はセーラームーンを描いていないイラストレーターが、あたかもsailormoonredrawをやったかのような画像」を生成することです。

これによって嬉しいのは「自分の好きなイラストレーターにsailormoonredrawをやって欲しかったな～、でもやってないしな～(ﾁﾗｯ」という願いを持っている人が、イラストレーター本人の手を煩わせずにその願いを実現できるということです。

私はカントクさんというイラストレーターの方が好きなのですが、sailormoonredrawをやっておられないようです。それならば自分で作ってしまおうというのが動機です。

# どうやって画像生成をやるのか
基本的には画像生成ニューラルネットワークモデルである[Generative Adversarial Networks(GANs)](https://papers.nips.cc/paper/5423-generative-adversarial-nets)とその発展系のモデル(DCGAN, StyleGAN等)を使います。

画像生成モデルに関してはここには書ききれない話なので、各位で調べて頂けると助かります。
